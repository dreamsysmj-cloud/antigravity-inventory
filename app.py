import streamlit as st
# Force update for deployment trigger
import pandas as pd
import plotly.express as px
import os
import glob
from datetime import datetime, timedelta
import database
import sqlite3

# --------------------------------------------------------------------------------
# Constants & Setup
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="ë¬¼ë¥˜ ì¬ê³ /ë§¤ì¶œ í†µí•© ê´€ë¦¬ (DB ê¸°ë°˜)",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Load Custom CSS
def local_css(file_name):
    if os.path.exists(file_name):
        with open(file_name, encoding='utf-8') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
local_css("styles.css")

# Ensure DB is initialized
database.init_db()

# --------------------------------------------------------------------------------
# Helper Functions
# --------------------------------------------------------------------------------
@st.cache_data
def load_latest_file():
    base_dir = os.path.join(os.getcwd(), "data")
    if not os.path.exists(base_dir): return None, "ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    files = glob.glob(os.path.join(base_dir, "**", "*í†µí•©ë°ì´í„°.xlsx"), recursive=True)
    if not files: return None, "í†µí•© ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    files.sort(key=os.path.getmtime, reverse=True)
    return files[0], None

def map_products_strict(df):
    """
    DBì— ìˆëŠ” í’ˆëª©ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì œê±°í•©ë‹ˆë‹¤.
    """
    mapped_list = []
    
    for idx, row in df.iterrows():
        company = row.get('ì—…ì²´')
        code = row.get('ì½”ë“œ')
        
        # ìˆœìˆ˜ DB ì¡°íšŒ
        product_info = database.find_product_by_code(company, code)
        
        if product_info:
            pid, name, std, price, pack_qty = product_info
            new_row = row.to_dict()
            new_row['í’ˆëª…(í‘œì¤€)'] = name
            new_row['ê·œê²©(í‘œì¤€)'] = std
            new_row['ë§¤ì…ë‹¨ê°€'] = price
            new_row['ì…ìˆ˜'] = pack_qty
            new_row['PID'] = pid
            mapped_list.append(new_row)
        # else: DBì— ì—†ìœ¼ë©´ ê³¼ê°íˆ ë²„ë¦¼ (User Request)
            
    return pd.DataFrame(mapped_list)

@st.cache_data(show_spinner=False)
def process_excel_file(file_path):
    xls = pd.ExcelFile(file_path)
    sheet_names = xls.sheet_names
    
    stock_rows = []
    sales_rows = []
    
    for sheet in sheet_names:
        try:
            raw_df = pd.read_excel(xls, sheet_name=sheet, header=None)
            
            # Header Finding
            header_idx = -1
            for idx, row in raw_df.head(10).iterrows():
                row_str = " ".join(row.astype(str).values)
                if "ì½”ë“œ" in row_str and ("ìˆ˜ëŸ‰" in row_str or "ì¬ê³ " in row_str or "ì…ìˆ˜" in row_str):
                    header_idx = idx
                    break
            
            if header_idx != -1:
                df = raw_df.iloc[header_idx+1:].copy()
                df.columns = raw_df.iloc[header_idx].astype(str).str.strip()
            else:
                df = raw_df
                
            company = "ê¸°íƒ€"
            if "í•˜ì€" in sheet: company = "í•˜ì€"
            elif "í•œêµ­" in sheet: company = "í•œêµ­"
            elif "ë‹¤ì´ì†Œ" in sheet: company = "ë‹¤ì´ì†Œ"
            elif "ê°€ì˜¨" in sheet: company = "ê°€ì˜¨"
            
            # Normalize
            col_code = next((c for c in df.columns if "ì½”ë“œ" in c), None)
            col_qty = next((c for c in df.columns if "ìˆ˜ëŸ‰" in c or "ì¬ê³ " in c), None)
            
            if col_code and col_qty:
                df = df.rename(columns={col_code: 'ì½”ë“œ', col_qty: 'ìˆ˜ëŸ‰'})
                df['ìˆ˜ëŸ‰'] = pd.to_numeric(df['ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
                df['ì—…ì²´'] = company
                
                target_df = df[['ì—…ì²´', 'ì½”ë“œ', 'ìˆ˜ëŸ‰']].copy() # í’ˆëª…ì€ ì–´ì°¨í”¼ DBì—ì„œ ê°€ì ¸ì˜´
                
                if "íŒë§¤" in sheet or "ë§¤ì¶œ" in sheet:
                    sales_rows.append(target_df)
                else:
                    stock_rows.append(target_df)
                    
        except Exception as e:
            print(f"Sheet error {sheet}: {e}")

    # Merge
    stock_df = pd.concat(stock_rows, ignore_index=True) if stock_rows else pd.DataFrame()
    sales_df = pd.concat(sales_rows, ignore_index=True) if sales_rows else pd.DataFrame()
    
    # Map to DB strict
    stock_df = map_products_strict(stock_df)
    sales_df = map_products_strict(sales_df)
    
    return stock_df, sales_df

def get_db_sales_analysis(start_date, end_date):
    """
    ê¸°ê°„ë³„ íŒë§¤ ë¶„ì„ ë°ì´í„° ìƒì„±
    """
    conn = database.get_connection()
    
    # Products + Sales Join query
    query = f"""
        SELECT 
            p.name as í’ˆëª…,
            p.standard as ê·œê²©,
            p.unit_price as ë‹¨ê°€,
            p.pack_qty as ì…ìˆ˜,
            SUM(s.qty) as ì´íŒë§¤ëŸ‰
        FROM sales_history s
        JOIN products p ON s.product_id = p.id
        WHERE s.date >= '{start_date}' AND s.date <= '{end_date}'
        GROUP BY p.id
    """
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    if df.empty:
        return pd.DataFrame()
        
    # Stats logic
    start_dt = pd.to_datetime(start_date)
    end_dt = pd.to_datetime(end_date)
    days = (end_dt - start_dt).days + 1
    months = days / 30.0 if days > 0 else 1
    
    df['ì›”í‰ê· '] = df['ì´íŒë§¤ëŸ‰'] / months
    df['ì¼í‰ê· '] = df['ì´íŒë§¤ëŸ‰'] / days
    
    return df

# --------------------------------------------------------------------------------
# Main UI & Navigation
# --------------------------------------------------------------------------------
st.title("ğŸ“¦ ë¬¼ë¥˜ í†µí•© ê´€ë¦¬ (Strict Mode)")
st.markdown(f"**{datetime.now().strftime('%Y-%m-%d')}**")

# Initialize Session State for View Navigation
if 'view' not in st.session_state:
    st.session_state['view'] = 'í˜„ì¬ ì¬ê³ '

# Top Navigation Buttons
c1, c2, c3, c4 = st.columns(4)
if c1.button("ğŸ“¦ í˜„ì¬ ì¬ê³ ", use_container_width=True, type="primary" if st.session_state['view']=='í˜„ì¬ ì¬ê³ ' else "secondary"):
    st.session_state['view'] = 'í˜„ì¬ ì¬ê³ '
    st.rerun()
if c2.button("ğŸ—ƒï¸ ì¬ê³  DB", use_container_width=True, type="primary" if st.session_state['view']=='ì¬ê³  DB' else "secondary"):
    st.session_state['view'] = 'ì¬ê³  DB'
    st.rerun()
if c3.button("ğŸ”„ í†µí•©ë°ì´í„°", use_container_width=True, type="primary" if st.session_state['view']=='í†µí•©ë°ì´í„°' else "secondary"):
    st.session_state['view'] = 'í†µí•©ë°ì´í„°'
    st.rerun()
if c4.button("ğŸ“ˆ íŒë§¤ ì´ë ¥ ë¶„ì„", use_container_width=True, type="primary" if st.session_state['view']=='íŒë§¤ ì´ë ¥ ë¶„ì„' else "secondary"):
    st.session_state['view'] = 'íŒë§¤ ì´ë ¥ ë¶„ì„'
    st.rerun()

st.markdown("---")

# --------------------------------------------------------------------------------
# View Logic
# --------------------------------------------------------------------------------

# Common Data Loading (Used in Current Inventory & Integrated Data)
def get_current_data():
    f_path, err = load_latest_file()
    if f_path:
        return process_excel_file(f_path)
    return pd.DataFrame(), pd.DataFrame()

# 1. View: í˜„ì¬ ì¬ê³  (Existing Logic)
if st.session_state['view'] == 'í˜„ì¬ ì¬ê³ ':
    st.subheader("ğŸ“¦ í˜„ì¬ ì¬ê³  í˜„í™©")
    
    stock_df, sales_df = get_current_data()
    
    if not stock_df.empty:
        # Summary
        c1, c2, c3 = st.columns(3)
        c1.metric("ì´ ì¬ê³ ëŸ‰", f"{stock_df['ìˆ˜ëŸ‰'].sum():,.0f}")
        c2.metric("ì´ ì¬ê³ ê¸ˆì•¡ (ì¶”ì •)", f"{(stock_df['ìˆ˜ëŸ‰'] * stock_df['ë§¤ì…ë‹¨ê°€']).sum():,.0f}ì›")
        c3.metric("í‘œì‹œ í’ˆëª© ìˆ˜", f"{len(stock_df):,}ê°œ")
        
        st.dataframe(
            stock_df[['í’ˆëª…(í‘œì¤€)', 'ê·œê²©(í‘œì¤€)', 'ì—…ì²´', 'ìˆ˜ëŸ‰', 'ë§¤ì…ë‹¨ê°€', 'ì…ìˆ˜']].sort_values('í’ˆëª…(í‘œì¤€)'), 
            use_container_width=True, 
            height=600
        )
    else:
        st.info("í‘œì‹œí•  ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í¬ë¡¤ë§ íŒŒì¼ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆê±°ë‚˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤)")

# 2. View: ì¬ê³  DB (Master DB Management)
elif st.session_state['view'] == 'ì¬ê³  DB':
    st.subheader("ğŸ—ƒï¸ í’ˆëª© ë§ˆìŠ¤í„° DB ê´€ë¦¬")
    
    # Upload Toggle
    if st.toggle("ğŸ“¤ í’ˆëª© ë§ˆìŠ¤í„° íŒŒì¼ ì—…ë¡œë“œ (ë¬¼ë¥˜ db íŒŒì¼.xlsx)", value=False):
        uploaded_db = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì„ íƒ", type=['xlsx'], key="master_uploader")
        if uploaded_db:
            if st.button("DB ì—…ë¡œë“œ ì‹¤í–‰"):
                with st.spinner("DB ì—…ë°ì´íŠ¸ ì¤‘..."):
                    try:
                        df = pd.read_excel(uploaded_db)
                        df.columns = df.columns.astype(str).str.replace('\n', '').str.replace(' ', '')
                        
                        rename_map = {
                            'ë§¤ì…ë‹¨ê°€(vatë¯¸í¬í•¨)': 'ë§¤ì…ë‹¨ê°€',
                            'í•˜ì€ì½”ë“œ': 'í•˜ì€ì½”ë“œ',
                            'í•œêµ­ì½”ë“œ': 'í•œêµ­ì½”ë“œ',
                            'í’ˆëª…': 'í’ˆëª…',
                            'ê·œê²©': 'ê·œê²©',
                        }
                        df = df.rename(columns=rename_map)
                        
                        success_count = 0
                        progress_bar = st.progress(0)
                        total = len(df)
                        
                        for idx, row in df.iterrows():
                            if pd.isna(row.get('í’ˆëª…')) and pd.isna(row.get('í•˜ì€ì½”ë“œ')) and pd.isna(row.get('í•œêµ­ì½”ë“œ')):
                                continue
                            database.upsert_product_strict(row)
                            success_count += 1
                            if idx % 10 == 0: progress_bar.progress(min(idx / total, 1.0))
                        
                        progress_bar.progress(1.0)
                        st.success(f"ì™„ë£Œ! {success_count}ê°œ í’ˆëª© ì—…ë°ì´íŠ¸ë¨.")
                        st.cache_data.clear()
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜: {e}")

    # Show DB Table
    conn = database.get_connection()
    db_df = pd.read_sql_query("SELECT * FROM products ORDER BY name", conn)
    conn.close()
    
    st.markdown(f"**ì´ ë“±ë¡ í’ˆëª©: {len(db_df)}ê°œ**")
    st.dataframe(db_df, use_container_width=True, height=600)

# 3. View: í†µí•©ë°ì´í„° (Crawling Data & Company Filter)
elif st.session_state['view'] == 'í†µí•©ë°ì´í„°':
    st.subheader("ğŸ”„ í†µí•© ë°ì´í„° ìƒì„¸ ë³´ê¸° (ì¬ê³ /íŒë§¤)")
    
    # Upload Toggle
    uploaded_crawl = None
    if st.toggle("ğŸ“¤ í†µí•© ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (í¬ë¡¤ë§ ê²°ê³¼)", value=False):
        uploaded_crawl = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì„ íƒ", type=['xlsx'], key="crawl_uploader")
    
    stock_df = pd.DataFrame()
    sales_current_df = pd.DataFrame()
    
    if uploaded_crawl:
        stock_df, sales_current_df = process_excel_file(uploaded_crawl)
        st.success("ì—…ë¡œë“œëœ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        f_path, err = load_latest_file()
        if f_path: 
            st.info(f"ì„œë²„ ìµœì‹  íŒŒì¼ ì‚¬ìš©: {os.path.basename(f_path)}")
            stock_df, sales_current_df = process_excel_file(f_path)
            
    if not stock_df.empty or not sales_current_df.empty:
        # ----------------------------------------------------------------
        # Search Bar (Reverted to Single Bar)
        # ----------------------------------------------------------------
        c_search1, c_search2 = st.columns([1, 4])
        search_cat = c_search1.selectbox("ê²€ìƒ‰ ê¸°ì¤€", ["ì „ì²´", "ì—…ì²´", "í’ˆëª…", "ì½”ë“œ"], key="search_cat")
        search_kw = c_search2.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="search_kw")
        
        st.write("---")

        # ----------------------------------------------------------------
        # Data Viewer (Quick Filters)
        # ----------------------------------------------------------------
        # Radio buttons for selecting view mode
        view_options = [
            "ì „ì²´ ì¬ê³ ", "ì „ì²´ íŒë§¤",
            "í•˜ì€ ì¬ê³ ", "í•˜ì€ íŒë§¤", 
            "í•œêµ­ ì¬ê³ ", "í•œêµ­ íŒë§¤", 
            "ë‹¤ì´ì†Œ ì¬ê³ ", "ë‹¤ì´ì†Œ íŒë§¤",
            "ê°€ì˜¨ ì¬ê³ ", "ê°€ì˜¨ íŒë§¤"
        ]
        
        selected_view = st.radio("ë°ì´í„° ë³´ê¸° ì„ íƒ", view_options, horizontal=True, index=0)
        
        # 1. Base Data Construction
        # Add 'Type' column for differentiation
        stock_df['êµ¬ë¶„'] = 'ì¬ê³ '
        sales_current_df['êµ¬ë¶„'] = 'íŒë§¤'
        
        combined_df = pd.concat([stock_df, sales_current_df], ignore_index=True)
        
        # 2. Filter by View Selection (Quick Filter)
        target_df = pd.DataFrame()
        
        if "ì „ì²´ ì¬ê³ " in selected_view:
            target_df = combined_df[combined_df['êµ¬ë¶„'] == 'ì¬ê³ ']
        elif "ì „ì²´ íŒë§¤" in selected_view:
            target_df = combined_df[combined_df['êµ¬ë¶„'] == 'íŒë§¤']
        else:
            # "í•˜ì€ ì¬ê³ ", "í•˜ì€ íŒë§¤" etc.
            parts = selected_view.split()
            v_comp = parts[0]
            v_type = parts[1]
            target_df = combined_df[
                (combined_df['ì—…ì²´'] == v_comp) & 
                (combined_df['êµ¬ë¶„'] == v_type)
            ]
            
        # 3. Apply Search Filter
        if search_kw:
            if search_cat == "ì „ì²´":
                # Search across all columns (convert to string first)
                mask = target_df.astype(str).apply(lambda x: x.str.contains(search_kw, case=False)).any(axis=1)
                target_df = target_df[mask]
            elif search_cat == "ì—…ì²´":
                target_df = target_df[target_df['ì—…ì²´'].astype(str).str.contains(search_kw, case=False)]
            elif search_cat == "í’ˆëª…":
                # Use 'í’ˆëª…(í‘œì¤€)' which is guaranteed from strict mapping
                target_df = target_df[target_df['í’ˆëª…(í‘œì¤€)'].astype(str).str.contains(search_kw, case=False)]
            elif search_cat == "ì½”ë“œ":
                target_df = target_df[target_df['ì½”ë“œ'].astype(str).str.contains(search_kw, case=False)]
        
        # Display Result
        st.markdown(f"**ì¡°íšŒëœ ë°ì´í„°: {len(target_df)}ê±´**")
        
        # Columns to show
        cols = ['êµ¬ë¶„', 'ì—…ì²´', 'ì½”ë“œ', 'í’ˆëª…(í‘œì¤€)', 'ê·œê²©(í‘œì¤€)', 'ìˆ˜ëŸ‰', 'ë§¤ì…ë‹¨ê°€', 'ì…ìˆ˜']
        
        st.dataframe(
            target_df[cols].sort_values(['ì—…ì²´', 'í’ˆëª…(í‘œì¤€)']), 
            use_container_width=True, 
            height=600
        )
        
    else:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# 4. View: íŒë§¤ ì´ë ¥ ë¶„ì„
elif st.session_state['view'] == 'íŒë§¤ ì´ë ¥ ë¶„ì„':
    st.subheader("ğŸ“… ê¸°ê°„ë³„ íŒë§¤ ë¶„ì„")
    st.markdown("DBì— ì €ì¥ëœ ê³¼ê±° íŒë§¤ ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ **ì›”í‰ê· /ì¼í‰ê· **ì„ ê³„ì‚°í•©ë‹ˆë‹¤.")
    
    c_d1, c_d2 = st.columns(2)
    start_d = c_d1.date_input("ì‹œì‘ì¼", datetime(2025, 11, 1))
    end_d = c_d2.date_input("ì¢…ë£Œì¼", datetime.today())
    
    if start_d <= end_d:
        df_anal = get_db_sales_analysis(start_d, end_d)
        
        if not df_anal.empty:
            st.markdown(f"**{start_d} ~ {end_d} ({len(df_anal)}ê°œ í’ˆëª©)**")
            st.dataframe(
                df_anal.style.format({
                    "ë§¤ì…ë‹¨ê°€": "{:,.0f}",
                    "ì´íŒë§¤ëŸ‰": "{:,.0f}",
                    "ì›”í‰ê· ": "{:,.1f}",
                    "ì¼í‰ê· ": "{:,.1f}"
                }).background_gradient(subset=['ì›”í‰ê· '], cmap="Greens"),
                use_container_width=True,
                height=600
            )
        else:
            st.warning("ì„ íƒí•œ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” íŒë§¤ ì´ë ¥ì´ DBì— ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("ì¢…ë£Œì¼ì´ ì‹œì‘ì¼ë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤.")
